from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import os,time
import FinanceDataReader as fdr

URL = "https://search.naver.com/search.naver?ssc=tab.news.all&where=news&sm=tab_jum&query="

def create_driver(stock_code : str) :
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("User-Agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36")
    options.add_argument("--window-size=1920,1080")

    try:
        # [í•µì‹¬ ìˆ˜ì •] ì„œë²„ì— ì´ë¯¸ ì„¤ì¹˜ëœ ë“œë¼ì´ë²„ê°€ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists("/usr/bin/chromedriver"):
            # Streamlit Cloud ì„œë²„ìš© ê²½ë¡œ (ë‹¤ìš´ë¡œë“œ ì•ˆ í•˜ê³  ì´ê±° ì”€)
            service = Service("/usr/bin/chromedriver")
            print("ğŸ–¥ï¸ ì„œë²„ í™˜ê²½ ê°ì§€: ì‹œìŠ¤í…œ ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            # ë‚´ ì»´í“¨í„°ìš© (ìë™ ë‹¤ìš´ë¡œë“œ)
            service = Service(ChromeDriverManager().install())
            print("ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€: ë“œë¼ì´ë²„ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

        df = fdr.StockListing('KRX')
        row = df[df['Code'] == stock_code]
        stock_name = row.iloc[0]['Name']
        driver = webdriver.Chrome(service=service, options=options)
        driver.get(URL + stock_name)
        return driver
        
    except Exception as e:
        print(f"âŒ í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì—ëŸ¬: {e}")
        raise e


def page_scroll(driver) :
    target_count = 150
    prev_height = driver.execute_script("return document.body.scrollHeight")
    
    while True :
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        articles = driver.find_elements(By.CSS_SELECTOR, 'a[data-heatmap-target=".tit"]')
        current_count = len(articles)
        
        if current_count >= target_count :
            break
        
        curr_height = driver.execute_script("return document.body.scrollHeight")
        if curr_height == prev_height :
            break
        
        prev_height = curr_height

def get_title_link(driver) :
    title_link_dict = {}
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')

    tags = soup.select('a[data-heatmap-target=".tit"]')

    if not tags:
        print("ì†ì„± ê²€ìƒ‰ ì‹¤íŒ¨, span íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        # span íƒœê·¸ë¥¼ ë¨¼ì € ì°¾ê³ , ê·¸ ë¶€ëª¨ì¸ a íƒœê·¸ë¥¼ ê°€ì ¸ì˜´
        spans = soup.select("span.sds-comps-text-type-headline1")
        tags = [span.find_parent("a") for span in spans if span.find_parent("a")]

    for tag in tags:
        # ì œëª© ê°€ì ¸ì˜¤ê¸° (íƒœê·¸ ì•ˆì˜ í…ìŠ¤íŠ¸)
        title = tag.get_text(strip=True)
        # ë§í¬ ê°€ì ¸ì˜¤ê¸°
        link = tag.get("href")
        
        if link:
            title_link_dict[title] = link
        
    return title_link_dict